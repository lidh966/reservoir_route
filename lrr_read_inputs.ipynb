{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/donghui/Box Sync/Research/PhD/Projects/Water_Supply_Drought'\n",
    "data_dir = f'{base_dir}/data'\n",
    "\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Grids & Sort by Upstream-Downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Read geo files related to a given HUC4 basin ---- #\n",
    "\n",
    "huc4 = '0601'\n",
    "\n",
    "nhd_data_dir = '/Users/donghui/Box Sync/Research/PhD/Projects/Drought_Cycle_Analysis/Data'\n",
    "crs = 'EPSG:4326'\n",
    "huc2_conus = [f'0{i}' if i<10 else f'{i}' for i in range(1, 19)]\n",
    "\n",
    "# read HUCs\n",
    "huc2 = huc4[0:2]\n",
    "gdb_file = f'{nhd_data_dir}/Raw/WBD/WBD_{huc2}_HU2_GDB.gdb'\n",
    "gdf_huc2_all = gpd.read_file(gdb_file, layer='WBDHU2')\n",
    "gdf_huc4_all = gpd.read_file(gdb_file, layer='WBDHU4')\n",
    "gdf_huc6_all = gpd.read_file(gdb_file, layer='WBDHU6')\n",
    "gdf_huc8_all = gpd.read_file(gdb_file, layer='WBDHU8')\n",
    "gdf_huc10_all = gpd.read_file(gdb_file, layer='WBDHU10')\n",
    "\n",
    "# set crs\n",
    "gdf_huc2_all = gdf_huc2_all.set_crs(crs, inplace=False, allow_override=True)    # includes the huc2 region\n",
    "gdf_huc4_all = gdf_huc4_all.set_crs(crs, inplace=False, allow_override=True)    # includes all huc4 subregions in this huc2 region\n",
    "gdf_huc6_all = gdf_huc6_all.set_crs(crs, inplace=False, allow_override=True)    # includes all huc6 basins in this huc2 region\n",
    "gdf_huc8_all = gdf_huc8_all.set_crs(crs, inplace=False, allow_override=True)    # includes all huc8 subbasins in this huc2 region\n",
    "gdf_huc10_all = gdf_huc10_all.set_crs(crs, inplace=False, allow_override=True)    # includes all huc10 subbasins in this huc2 region\n",
    "\n",
    "########## Prepare flow lines ##########\n",
    "\n",
    "if huc2 == '03':    # multiple NHDP files for 03\n",
    "    flow_attr_file_list = [f'{nhd_data_dir}/Raw/NHDPlus/NHDPlus{huc2}{i}/NHDPlusAttributes' for i in ['N','S','W']]\n",
    "    hydro_file_list = [f'{nhd_data_dir}/Raw/NHDPlus/NHDPlus{huc2}{i}/NHDSnapshot/Hydrography' for i in ['N','S','W']]\n",
    "elif huc2 == '10': \n",
    "    flow_attr_file_list = [f'{nhd_data_dir}/Raw/NHDPlus/NHDPlus{huc2}{i}/NHDPlusAttributes' for i in ['U','L']]\n",
    "    hydro_file_list = [f'{nhd_data_dir}/Raw/NHDPlus/NHDPlus{huc2}{i}/NHDSnapshot/Hydrography' for i in ['U','L']]\n",
    "else:\n",
    "    flow_attr_file_list = [f'{nhd_data_dir}/Raw/NHDPlus/NHDPlus{huc2}/NHDPlusAttributes']\n",
    "    hydro_file_list = [f'{nhd_data_dir}/Raw/NHDPlus/NHDPlus{huc2}/NHDSnapshot/Hydrography']\n",
    "\n",
    "gdf_flow_list = []\n",
    "for flow_attr_file, hydro_file in zip(flow_attr_file_list, hydro_file_list):\n",
    "    gdf_fline_vaa = gpd.read_file(flow_attr_file, layer='PlusFlowlineVAA')\n",
    "    gdf_fline = gpd.read_file(hydro_file, layer='NHDFlowline')\n",
    "\n",
    "    # change COMID to ComID if the error exists\n",
    "    if not 'ComID' in gdf_fline:\n",
    "        gdf_fline.rename(columns={'COMID':'ComID'}, inplace=True)\n",
    "\n",
    "    # change vaa file ComID to int\n",
    "    to_int_var = ['ComID', 'StreamOrde', 'StreamCalc']\n",
    "    gdf_fline_vaa[to_int_var] = gdf_fline_vaa[to_int_var].astype(int)\n",
    "\n",
    "    # merge this two gdfs\n",
    "    to_merge_vars = ['ComID', 'StreamOrde', 'StreamCalc', 'FromNode', 'ToNode']\n",
    "    gdf_flow = gdf_fline.merge(gdf_fline_vaa[to_merge_vars], how='inner', on='ComID')\n",
    "    \n",
    "    gdf_flow_list.append(gdf_flow)\n",
    "\n",
    "gdf_flow = pd.concat(gdf_flow_list)\n",
    "\n",
    "# set crs\n",
    "gdf_flow = gdf_flow.set_crs(crs, inplace=True, allow_override=True)\n",
    "\n",
    "# subset to the target huc4\n",
    "gdf_flow_huc4 = gdf_flow.sjoin(gdf_huc4_all.loc[gdf_huc4_all['huc4']==huc4], how='inner', predicate='intersects')\n",
    "\n",
    "########## End Prepare flow lines ##########\n",
    "\n",
    "\n",
    "########## Read .nc files ##########\n",
    "conus_grid_nc = f'{data_dir}/processed/LRR/input/conus_nldas_grid.nc'\n",
    "conus_reservoir_nc = f'{data_dir}/processed/LRR/input/reservoirs.nc'\n",
    "# Read CONUS grids\n",
    "with nc.Dataset(conus_grid_nc) as conus_grid:\n",
    "    lon_array = conus_grid.variables['lon'][:]\n",
    "    lat_array = conus_grid.variables['lat'][:]\n",
    "    grid_id_array = conus_grid.variables['id'][:, :]\n",
    "    flow_dir_array = conus_grid.variables['flow_dir'][:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhd_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "\n",
    "def get_grids_in_hu(lon_array, lat_array, gdf_huc):\n",
    "    \"\"\"\n",
    "    Get grids (lon-lat) within the target HU\n",
    "    \n",
    "    gdf_huc: geodataframe of the target HU\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # create lon-lat pairs from global vars: lon_array and lat_array\n",
    "    lon_lat_all = [[Point(lon, lat), i, j] for i, lon in enumerate(lon_array) for j, lat in enumerate(lat_array)]    # [Point(lon, lat), i-lon index, j-lat index]\n",
    "    \n",
    "    # index the wanted hu from the gdf\n",
    "    huc_geo = gdf_huc['geometry'].values   # the polygon for this huc\n",
    "        \n",
    "    # find (lon, lat) pairs within the area\n",
    "    lon_lat_sub = [i for i in lon_lat_all if huc_geo.contains(i[0])[0]]\n",
    "\n",
    "    # create point geodataframe for selected points and check\n",
    "    d = {'lon index': [i[1] for i in lon_lat_sub], 'lat index': [i[2] for i in lon_lat_sub]}\n",
    "    gdf_points = gpd.GeoDataFrame(d, \n",
    "                                  geometry=[i[0] for i in lon_lat_sub], crs='EPSG:4326')   # lon index, lat index, geometry\n",
    "    \n",
    "    result = {\n",
    "        'grids_in_hu': gdf_points,    # gdf - lon index, lat index, geometry; the index represents index in .nc files\n",
    "        'others': (lon_array, lat_array, gdf_huc)    # this is mainly for plot check\n",
    "    }\n",
    "    \n",
    "    return(result)\n",
    "\n",
    "def get_downstream_cell(i, j, direction):\n",
    "    \"\"\"\n",
    "    Returns the downstream cell coordinates based on D8 flow direction.\n",
    "    d8 directions:\n",
    "    32  64 128\n",
    "    16  x   1\n",
    "    8   4   2\n",
    "\n",
    "    Parameters:\n",
    "    i (int): Row index of the current cell\n",
    "    j (int): Column index of the current cell\n",
    "    direction (int): D8 flow direction code of the current cell\n",
    "\n",
    "    Returns:\n",
    "    tuple: Coordinates (row, col) of the downstream cell, or None if no downstream\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the changes in row (di) and column (dj) for each flow direction\n",
    "    # PLEASE note: the direction is defined as such, because the latitude array increases as the row index increases & longitude array increases as the col index increases!!!\n",
    "\n",
    "    direction_map = {\n",
    "        1: (0, 1),     # East: i, j+1\n",
    "        2: (-1, 1),    # Southeast: i-1, j+1\n",
    "        4: (-1, 0),    # South: i-1, j (move south, decrease row index)\n",
    "        8: (-1, -1),   # Southwest: i-1, j-1\n",
    "        16: (0, -1),   # West: i, j-1\n",
    "        32: (1, -1),   # Northwest: i+1, j-1\n",
    "        64: (1, 0),    # North: i+1, j (move north, increase row index)\n",
    "        128: (1, 1)    # Northeast: i+1, j+1\n",
    "    }\n",
    "\n",
    "\n",
    "    # Get the changes in row and column for the given direction\n",
    "    di, dj = direction_map.get(direction, (0, 0))    # if direction is not in the direction_map, return (0, 0)\n",
    "\n",
    "    # If di and dj are both 0, it means the direction is not defined (e.g., a sink)\n",
    "    if di == 0 and dj == 0:\n",
    "        return None\n",
    "\n",
    "    # Calculate the coordinates of the downstream cell\n",
    "    downstream_i = i + di\n",
    "    downstream_j = j + dj\n",
    "    \n",
    "    return (downstream_i, downstream_j)\n",
    "\n",
    "# test\n",
    "get_downstream_cell(2, 16, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the grids within the target HU\n",
    "gdf_huc4 = gdf_huc4_all.loc[gdf_huc4_all['huc4']==huc4]\n",
    "gdf_grid_index_in_hu = get_grids_in_hu(lon_array, lat_array, gdf_huc4)['grids_in_hu']\n",
    "lon_index = gdf_grid_index_in_hu['lon index'].values    # contains duplicate values\n",
    "lat_index = gdf_grid_index_in_hu['lat index'].values    # contains duplicate values\n",
    "\n",
    "# Subset the flow direction array to the target HU basin (the rectangular area covering the HUC4 basin)\n",
    "# technically, I didn't \"subset\", just set the flow direction values outside the HU to -9999\n",
    "# first, set all conus grids outside the target HU to -9999\n",
    "mask = np.ones_like(flow_dir_array, dtype=bool)\n",
    "mask[lat_index, lon_index] = False\n",
    "flow_dir_array[mask] = -1    # set all conus grids outside the target HU to -1\n",
    "# second, subset the flow direction array to the target HU basin\n",
    "lat_index_unique = np.unique(lat_index)\n",
    "lon_index_unique = np.unique(lon_index)\n",
    "flow_dir_array_huc4 = flow_dir_array[np.ix_(lat_index_unique, lon_index_unique)]\n",
    "\n",
    "# also, get the grid id array for the target HU basin for record\n",
    "grid_id_array_huc4 = grid_id_array[np.ix_(lat_index_unique, lon_index_unique)]\n",
    "lat_array_huc4 = lat_array[lat_index_unique]\n",
    "lon_array_huc4 = lon_array[lon_index_unique]\n",
    "\n",
    "########## Sort the grids ##########\n",
    "\n",
    "# create a graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# add nodes\n",
    "nrows, ncols = flow_dir_array_huc4.shape\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        # add node for each grid\n",
    "        # if the node flows out of the huc4 basin, skip\n",
    "        if flow_dir_array_huc4[i, j] == -1:\n",
    "            continue\n",
    "        \n",
    "        G.add_node((i, j), \n",
    "                   flow_dir=flow_dir_array_huc4[i, j], grid_id=grid_id_array_huc4[i, j], grid_lat=lat_array_huc4[i], grid_lon=lon_array_huc4[j])\n",
    "\n",
    "        # determine downstream grids and add edges\n",
    "        downstream_grid_ij = get_downstream_cell(i, j, flow_dir_array_huc4[i, j])\n",
    "\n",
    "        if downstream_grid_ij is not None and flow_dir_array_huc4[downstream_grid_ij] != -1:\n",
    "            # if downstream grid is not None AND the downstream grid is not outside the huc4 basin\n",
    "            G.add_edge((i, j), downstream_grid_ij)\n",
    "\n",
    "# typological sorting\n",
    "sorted_grid_list = list(nx.topological_sort(G))\n",
    "\n",
    "# store the sorted grid id and upstream grid id for each grid: {grid: [upstream grid list]}\n",
    "# the grid order is following the topological sorting\n",
    "upstream_grid_dict = {grid: [] for grid in sorted_grid_list}\n",
    "for grid in sorted_grid_list:\n",
    "    upstream_grid_dict[grid] = list(G.predecessors(grid))\n",
    "# convert the grid index in upstream_grid_dict to grid id (the grid attribute in the node)\n",
    "upstream_grid_id_dict = {G.nodes[grid]['grid_id']: [G.nodes[upstream_grid]['grid_id'] for upstream_grid in upstream_grid_dict[grid]] for grid in upstream_grid_dict}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "nodes = [(0,0), (0,1), (1,0), (2,0), (1,1)]\n",
    "G.add_nodes_from(nodes)\n",
    "edges = [((0,0), (1,0)), ((0,1), (1,0)), ((1,0), (2,0)), ((1,1), (2,0))]\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "# typological sorting\n",
    "sorted_grid_list = list(nx.topological_sort(G))\n",
    "\n",
    "# store the sorted grid id and upstream grid id for each grid: {grid: [upstream grid list]}\n",
    "# the grid order is following the topological sorting\n",
    "upstream_grid_dict = {grid: [] for grid in sorted_grid_list}\n",
    "for grid in sorted_grid_list:\n",
    "    upstream_grid_dict[grid] = list(G.predecessors(grid))\n",
    "\n",
    "upstream_grid_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Visualize the graph on the map ---- #\n",
    "\n",
    "nodes_data = pd.DataFrame.from_dict(dict(G.nodes(data=True)), orient='index')\n",
    "geometry = [Point(xy) for xy in zip(nodes_data['grid_lon'], nodes_data['grid_lat'])]\n",
    "gdf_nodes = gpd.GeoDataFrame(nodes_data, geometry=geometry, crs='EPSG:4326')\n",
    "\n",
    "\n",
    "# ------------------- Plot ------------------- #\n",
    "# Variables to store components of arrows\n",
    "x = []\n",
    "y = []\n",
    "dx = []\n",
    "dy = []\n",
    "\n",
    "default_lon = lon_array_huc4[0]\n",
    "default_lat = lat_array_huc4[0]\n",
    "for edge in G.edges():\n",
    "    start_node = G.nodes[edge[0]]\n",
    "    end_node = G.nodes[edge[1]]\n",
    "    try:\n",
    "        x_start, y_start = start_node['grid_lon'], start_node['grid_lat']\n",
    "        x_end, y_end = end_node['grid_lon'], end_node['grid_lat']\n",
    "    except KeyError:\n",
    "        x_start, y_start = default_lon, default_lat\n",
    "        x_end, y_end = default_lon, default_lat\n",
    "\n",
    "    x.append(x_start)\n",
    "    y.append(y_start)\n",
    "    dx.append(x_end - x_start)\n",
    "    dy.append(y_end - y_start)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot arrows\n",
    "ax.quiver(x, y, dx, dy, angles='xy', scale_units='xy', scale=1, color='gray')\n",
    "\n",
    "# Plot nodes\n",
    "gdf_nodes.plot(ax=ax, marker='o', color='black', alpha=0.7, markersize=10)\n",
    "\n",
    "gdf_huc4.plot(ax=ax, facecolor='none', edgecolor='tab:gray', linewidth=1)\n",
    "\n",
    "# plot flow line\n",
    "# specify to which stream order\n",
    "max_order = gdf_flow_huc4['StreamOrde'].max()\n",
    "min_order_to_keep = 4\n",
    "gdf_flow_huc4.loc[gdf_flow_huc4['StreamOrde']>=min_order_to_keep].plot(ax=ax, linewidth=1)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.zeros((3, 5), dtype=[\n",
    "    ('var_1', int),\n",
    "    ('var_2', float),\n",
    "    ('var_3', str)\n",
    "])\n",
    "\n",
    "grid = np.zeros((3, 5), dtype=[('grid_id', int), ('elevation', float), ('slope', float), ('runoff', float), ('inflow', float), ('outflow', float), ('storage', float), ('has_reservoir', bool), ('reservoir_id', 'U10')])\n",
    "\n",
    "\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Daily NLDAS Runoff .nc to Single Input File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Read NLDAS daily runoff data & combine to a single file ---- #\n",
    "\n",
    "nldas_runoff_dir = f'{data_dir}/processed/nldas_daily'\n",
    "\n",
    "nc_files_list = [f for f in os.listdir(nldas_runoff_dir) if f.endswith('.nc')]\n",
    "date_list = pd.to_datetime([f.split('.')[0] for f in nc_files_list]).sort_values().tolist()\n",
    "\n",
    "# get basic dimension info from the first nc file\n",
    "with nc.Dataset(f'{nldas_runoff_dir}/{nc_files_list[0]}') as daily_runoff:\n",
    "    lat_array_conus = daily_runoff.variables['lat'][:]\n",
    "    lon_array_conus = daily_runoff.variables['lon'][:]\n",
    "\n",
    "# create a new nc dataset\n",
    "combined_nc_file_path = f'{data_dir}/processed/LRR/input/nldas_runoff.nc'\n",
    "with nc.Dataset(combined_nc_file_path, 'w') as combined_nc:\n",
    "    # create dimensions\n",
    "    combined_nc.createDimension('time', len(date_list))\n",
    "    combined_nc.createDimension('lat', len(lat_array_conus))\n",
    "    combined_nc.createDimension('lon', len(lon_array_conus))\n",
    "\n",
    "    # create variables\n",
    "    combined_nc.createVariable('time', 'S10', ('time',))\n",
    "    combined_nc.createVariable('lat', 'f4', ('lat',))\n",
    "    combined_nc.createVariable('lon', 'f4', ('lon',))\n",
    "    combined_nc.createVariable('Qs', 'f8', ('time', 'lat', 'lon',))\n",
    "    combined_nc.createVariable('Qsb', 'f8', ('time', 'lat', 'lon',))\n",
    "\n",
    "    # variable attributes\n",
    "    combined_nc.variables['time'].units = 'none'\n",
    "    combined_nc.variables['time'].long_name = 'string datetime (yyyy-mm-dd) from 1980-01-01 to 2019-12-31'\n",
    "    combined_nc.variables['lat'].long_name = 'latitude'\n",
    "    combined_nc.variables['lon'].long_name = 'longitude'\n",
    "    combined_nc.variables['Qs'].long_name = 'surface runoff (mm/d)'\n",
    "    combined_nc.variables['Qsb'].long_name = 'baseflow (mm/d)'\n",
    "\n",
    "    # write data\n",
    "    combined_nc.variables['time'][:] = np.array(date_list).astype('datetime64[D]').astype(str)\n",
    "    combined_nc.variables['lat'][:] = lat_array_conus\n",
    "    combined_nc.variables['lon'][:] = lon_array_conus\n",
    "\n",
    "    # write runoff data from each nc file\n",
    "    for i, date in enumerate(date_list):\n",
    "        if i % 100 == 0:\n",
    "            print(f'Processing {date}')\n",
    "        year = date.year\n",
    "        month = f'{date.month:02d}'\n",
    "        day = f'{date.day:02d}'\n",
    "\n",
    "        nc_file_path = f'{nldas_runoff_dir}/{year}{month}{day}.nc'\n",
    "        with nc.Dataset(nc_file_path) as daily_runoff:\n",
    "            # PLEASE NOTE FOR THE RUNOFF DATA\n",
    "            # The runoff data in the original nc files are hourly average values for each day (mm/hr)\n",
    "            # So, here, I need to multiply the values by 24 to get the daily values (mm/day)\n",
    "            combined_nc.variables['Qs'][date_list.index(date), :, :] = daily_runoff.variables['Qs'][:] * 24    # convert from mm/hr to mm/day\n",
    "            combined_nc.variables['Qsb'][date_list.index(date), :, :] = daily_runoff.variables['Qsb'][:] * 24    # convert from mm/hr to mm/day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Test the runoff data ---- #\n",
    "\n",
    "with nc.Dataset(combined_nc_file_path) as conus_runoff:\n",
    "    # Qs = conus_runoff.variables['Qs'][:]\n",
    "    # Qsb = conus_runoff.variables['Qsb'][:]\n",
    "\n",
    "    time = conus_runoff.variables['time'][:]\n",
    "\n",
    "start_date = '1980-01-01'\n",
    "end_date = '1980-12-31'\n",
    "start_date_index = np.where(time==start_date)[0][0]\n",
    "end_date_index = np.where(time==end_date)[0][0]\n",
    "\n",
    "time_sub = time[start_date_index:end_date_index+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Observed Storage for Assimilation\n",
    "Concat all storage series of the 452 reservoirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ts_dir = '/Users/donghui/Box Sync/Research/PhD/Projects/DROM_CONUS_Analysis/Data/HydroShare/data_training'\n",
    "res_meta_file = f'/Users/donghui/Box Sync/Research/PhD/Projects/DROM_CONUS_Analysis/Data/HydroShare/reservoir_metadata.csv'\n",
    "\n",
    "df_res_meta = pd.read_csv(res_meta_file) \n",
    "\n",
    "# Initialize a dataframe\n",
    "df_storage_all = pd.DataFrame()\n",
    "\n",
    "res_ts_files = [f for f in os.listdir(res_ts_dir) if f.endswith('.csv')]\n",
    "for res_ts_file in res_ts_files:\n",
    "    gid = res_ts_file.split('.')[0]\n",
    "    df_res_i = pd.read_csv(f'{res_ts_dir}/{res_ts_file}')\n",
    "    df_res_i['Time'] = pd.to_datetime(df_res_i['Time'])\n",
    "    df_res_i.set_index('Time', inplace=True)\n",
    "\n",
    "    # remove duplicate indices\n",
    "    df_res_i = df_res_i[~df_res_i.index.duplicated(keep='first')]\n",
    "\n",
    "    # use metadata to convert normalized storage to actual storage\n",
    "    max_storage = df_res_meta.loc[df_res_meta['ID']==int(gid), 'Maximum Storage'].values[0]\n",
    "    df_res_i['Storage'] = df_res_i['Storage'] * max_storage\n",
    "\n",
    "    # merge to the combined dataframe\n",
    "    # rename for merge\n",
    "    df_res_i.rename(columns={'Storage': gid}, inplace=True)\n",
    "    df_storage_all = df_storage_all.merge(df_res_i[gid], how='outer', left_index=True, right_index=True)\n",
    "\n",
    "    # replace all NaN with -9999\n",
    "    df_storage_all.fillna(-9999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_storage_all.to_csv(f'{data_dir}/processed/LRR/input/reservoir_storage.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{data_dir}/processed/LRR/input/reservoir_storage.csv', index_col=0)\n",
    "df.index = pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_storage_assimilation(storage_file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read the reservoir storage time series file for assimilation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_storage_assimilation : pd.DataFrame\n",
    "        index: Time [pd.Timestamp]\n",
    "        cols: 'Reservoir gid' - reservoir storage [acft]\n",
    "    \"\"\"\n",
    "\n",
    "    df_storage_assimilation = pd.read_csv(storage_file_path, index_col=0)\n",
    "    df_storage_assimilation.index = pd.to_datetime(df_storage_assimilation.index)\n",
    "    return df_storage_assimilation\n",
    "\n",
    "storage_file_path = f'{data_dir}/processed/LRR/input/reservoir_storage.csv'\n",
    "df_storage_assimilation = read_storage_assimilation(storage_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "545: 0.0762488233206277\n",
      "223: 0.22556079794718978\n",
      "1774: 0.2352372386115238\n",
      "7311: 0.0281205561968869\n",
      "1006: 0.49457610435653815\n",
      "592: 0.0516711833785004\n",
      "753: 0.41810073660862757\n",
      "784: 0.0852216748768472\n",
      "948: 0.25041369\n",
      "974: 0.0003060042403444\n",
      "169: 0.2329598398213392\n",
      "97: 0.06568181818181809\n",
      "182: 0.139683478501\n",
      "431: 0.11689986459475143\n",
      "1827: 0.698705925827796\n",
      "1833: 0.3814427220325704\n",
      "419: 0.008830716376744884\n",
      "1600: 0.0388928546756626\n",
      "1615: 0.266118186852306\n",
      "41: 0.0\n",
      "55: 0.0451094306365261\n",
      "168: 0.7720074876049783\n",
      "975: 0.2808438737664546\n",
      "961: 0.3371327824400073\n",
      "1761: 0.3990247112150899\n",
      "1007: 0.0436563462814423\n",
      "1775: 0.4112100046985274\n",
      "546: 0.0\n",
      "1763: 0.4476906935732303\n",
      "7306: 0.915145360863515\n",
      "585: 0.07172418534304961\n",
      "963: 0.029205057502185695\n",
      "80: 0.2603775989999999\n",
      "94: 0.2520940341120013\n",
      "57: 0.0783933676194443\n",
      "1818: 0.3425645154737413\n",
      "1824: 0.5758326789578165\n",
      "368: 0.0\n",
      "1171: 0.20341685899999998\n",
      "1617: 0.3775576567111911\n",
      "396: 0.0045481336099235\n",
      "1164: 0.263883944\n",
      "1170: 0.239491223\n",
      "382: 0.007471018695821399\n",
      "355: 0.4877646286024945\n",
      "56: 0.0008699378059389\n",
      "42: 0.7885041725996286\n",
      "180: 0.41976204384050164\n",
      "157: 0.0598666984051416\n",
      "962: 0.1334369931952316\n",
      "792: 0.6266979337197469\n",
      "989: 0.2126343376818468\n",
      "1776: 0.3432405167644729\n",
      "1762: 0.5536164628768312\n",
      "7313: 0.5574033628714783\n",
      "1789: 0.3536356387767175\n",
      "557: 0.5073171805197948\n",
      "7317: 0.4307411485504149\n",
      "1000: 0.3955412817852831\n",
      "1014: 0.0001315418584985\n",
      "1216: 0.8960781523197656\n",
      "85: 0.3355022299141316\n",
      "609: 0.031269199676637\n",
      "153: 0.493515296514553\n",
      "806: 0.5350470057397615\n",
      "1835: 0.46828549756939913\n",
      "1809: 0.5486932791522251\n",
      "423: 0.2465739753292006\n",
      "437: 0.1049517887717401\n",
      "386: 8.809999999999999e-05\n",
      "1606: 0.328122625\n",
      "393: 0.2657293390386098\n",
      "387: 0.0035646646030900006\n",
      "378: 0.407413241\n",
      "1834: 0.1484806115610858\n",
      "185: 0.4808222604788475\n",
      "90: 0.0131033145958519\n",
      "967: 0.1948608563689716\n",
      "998: 0.0055942183566736\n",
      "768: 0.0010224948875255\n",
      "1767: 0.1009025826117757\n",
      "595: 0.2962103458565448\n",
      "1001: 0.48825585471761657\n",
      "1029: 0.621953184\n",
      "542: 0.7821328367892019\n",
      "554: 0.0228070239366256\n",
      "1017: 0.0423425507839472\n",
      "1003: 0.0508408847523597\n",
      "597: 0.333544754\n",
      "1765: 0.3987307814831582\n",
      "965: 0.0596200076103448\n",
      "1201: 0.1658171465307435\n",
      "92: 5.686664771111744e-05\n",
      "144: 0.10237207265699316\n",
      "193: 0.07554539667843288\n",
      "1822: 0.4486311892777713\n",
      "1188: 0.53210405946255\n",
      "391: 0.097026911\n",
      "1177: 0.4656363064032862\n",
      "385: 0.0\n",
      "1176: 0.5622474229456829\n",
      "384: 0.0891796718595919\n",
      "390: 0.1746202556561293\n",
      "421: 0.1822638185901684\n",
      "353: 0.25396401211473363\n",
      "1823: 0.7209904720501396\n",
      "78: 0.0\n",
      "192: 0.1351251878584646\n",
      "87: 0.0022682632065193\n",
      "780: 0.06486328927973758\n",
      "958: 0.0\n",
      "964: 0.0102735495801996\n",
      "1770: 0.2437259705942861\n",
      "1016: 0.0586535285698557\n",
      "1758: 0.6463915566501017\n",
      "541: 0.2963160846414077\n",
      "10003: 0.7694743090825144\n",
      "10017: 0.7662103227797523\n",
      "1273: 0.2779867139999999\n",
      "903: 0.0\n",
      "644: 0.057335451656831606\n",
      "1139: 0.1503048281851866\n",
      "1851: 0.5391208294846862\n",
      "1266: 0.41770290985014674\n",
      "10002: 0.0020335536349771\n",
      "1716: 0.3659602169409429\n",
      "533: 0.42050424294504896\n",
      "531: 0.0006134969325152998\n",
      "10028: 0.6692797235217263\n",
      "1714: 0.3145778936943269\n",
      "10014: 0.25354882358480735\n",
      "10000: 3.516130166493602e-05\n",
      "445: 0.0395753192798892\n",
      "451: 0.7074566615859359\n",
      "1847: 0.5538007178201687\n",
      "1112: 0.6408759676545295\n",
      "487: 0.8873951447141825\n",
      "1846: 0.4200202026784841\n",
      "1852: 0.31518123006788906\n",
      "450: 0.3611210352903814\n",
      "861: 0.1464925657643919\n",
      "929: 0.3773204827646089\n",
      "10001: 0.0\n",
      "10015: 0.0\n",
      "295: 0.3272381048463372\n",
      "10029: 0.209572269041183\n",
      "1067: 0.573160595\n",
      "518: 0.2972889852531869\n",
      "530: 0.3009596814037399\n",
      "10011: 0.0145763356359718\n",
      "1739: 0.0670467436516478\n",
      "10005: 0.0394389901823281\n",
      "10039: 0.13871196036801123\n",
      "1077: 0.438511294\n",
      "911: 0.0373327513675309\n",
      "1249: 0.013185288\n",
      "1275: 0.395462545\n",
      "656: 0.0004003523100328001\n",
      "1315: 0.4899632851783861\n",
      "1842: 0.6365720437268532\n",
      "1659: 0.3060660778089586\n",
      "497: 0.075754932502596\n",
      "1843: 0.2400943899317407\n",
      "469: 0.231579754\n",
      "870: 0.4265935145884293\n",
      "657: 0.08258064516129027\n",
      "131: 0.1883130224981866\n",
      "10038: 0.0029856687898088207\n",
      "10004: 0.0\n",
      "10010: 0.0249818971759594\n",
      "509: 0.4557643137122493\n",
      "537: 0.03358000558503207\n",
      "1048: 0.20505999\n",
      "10006: 0.0393712861797968\n",
      "1712: 0.1913129204360937\n",
      "1706: 0.0210998929884148\n",
      "292: 0.0322376012180925\n",
      "1060: 0.42136968300000005\n",
      "133: 0.5629893483925384\n",
      "1302: 0.469379387\n",
      "1841: 0.6323809523809524\n",
      "1699: 0.1425660955072719\n",
      "1855: 0.5256495179215428\n",
      "319: 0.046117044\n",
      "1869: 0.0450361650411705\n",
      "1896: 0.456001114\n",
      "1128: 0.070507844\n",
      "1883: 0.0366769044307022\n",
      "442: 0.0\n",
      "456: 0.1744584658187599\n",
      "1317: 0.1374514066570694\n",
      "898: 0.087359944\n",
      "132: 0.2305738804891038\n",
      "2193: 0.102525765\n",
      "1277: 0.23132973\n",
      "913: 0.1914534935000104\n",
      "907: 3.061132619069056e-05\n",
      "293: 0.0293270188124325\n",
      "1707: 0.1884426084610303\n",
      "1075: 0.6809187663350229\n",
      "1713: 0.0162987947026437\n",
      "10013: 0.0\n",
      "10007: 0.0\n",
      "536: 0.3679345726588337\n",
      "522: 0.2869684140663495\n",
      "1093: 0.069904933\n",
      "1050: 0.1558701923577625\n",
      "1044: 0.3367235179999999\n",
      "10022: 0.7383942588024219\n",
      "1078: 0.819221467143503\n",
      "10036: 0.510740531\n",
      "1291: 0.7441906641827217\n",
      "1285: 0.18280213799999998\n",
      "895: 0.4989770745326375\n",
      "2149: 0.04009122006841499\n",
      "473: 0.0057309718090767\n",
      "467: 0.007097584669470199\n",
      "1124: 0.210320547\n",
      "1125: 0.5495367748741593\n",
      "300: 0.49177134299999986\n",
      "664: 0.053375155640710555\n",
      "116: 0.072529224\n",
      "1247: 0.18593971\n",
      "10037: 0.5596648321994303\n",
      "10023: 0.9443200084323696\n",
      "1723: 0.5915220106548392\n",
      "1051: 0.5400173282070722\n",
      "1910: 0.645848375\n",
      "506: 0.0153223675977808\n",
      "1092: 0.0174045830132468\n",
      "1084: 0.0061708918809847\n",
      "10009: 0.1613578356304237\n",
      "1053: 0.249308024\n",
      "1735: 0.0165724196920737\n",
      "10035: 0.020556478405315597\n",
      "10021: 0.9487214549432518\n",
      "1709: 0.047159494987344\n",
      "1286: 0.0034276585217552\n",
      "1292: 0.0022167059953214\n",
      "1245: 0.249488471\n",
      "1279: 0.0001354752686331\n",
      "100: 0.3065786750802952\n",
      "114: 0.0112173458804752\n",
      "882: 0.3731237742427544\n",
      "470: 0.027768136\n",
      "316: 0.012202833241436143\n",
      "1872: 0.5173601777123877\n",
      "458: 0.251789077212806\n",
      "1655: 0.3777327225401563\n",
      "1127: 0.143455331\n",
      "1126: 0.023353348\n",
      "1654: 0.08867200533867191\n",
      "471: 0.0\n",
      "317: 0.3320679569999999\n",
      "1683: 0.3146110855917929\n",
      "854: 0.0361274651076619\n",
      "868: 0.07573947947604501\n",
      "2188: 0.4420585906571656\n",
      "920: 0.0\n",
      "1287: 0.6560977191637858\n",
      "10020: 0.029492702\n",
      "10034: 0.20263658602881218\n",
      "10008: 0.0007260406582768\n",
      "505: 0.16596921767501244\n",
      "511: 0.2802492495483063\n",
      "529: 0.0003072721065209\n",
      "1095: 0.06846374913601799\n",
      "10030: 0.8603630795506412\n",
      "1718: 0.1044895178109965\n",
      "10024: 0.8545288197621226\n",
      "1042: 0.48117574299999993\n",
      "10018: 0.08558923650510611\n",
      "1283: 0.3308577087141986\n",
      "1297: 0.1945696129404968\n",
      "924: 0.24468506354192968\n",
      "1254: 0.213354473\n",
      "893: 0.3260731725529499\n",
      "1863: 0.592867068\n",
      "449: 0.0456394392154281\n",
      "307: 0.4432642520950879\n",
      "1650: 0.4552102376599633\n",
      "1122: 0.116599769\n",
      "1645: 0.0850534328795198\n",
      "1123: 0.509687446\n",
      "306: 0.049462794\n",
      "1862: 0.316651501\n",
      "448: 0.190251572327044\n",
      "919: 0.494989484102437\n",
      "1269: 0.5269201226335758\n",
      "1296: 0.1033154\n",
      "10019: 0.1105732484076433\n",
      "10025: 0.9420254403131116\n",
      "10031: 0.8906244762511313\n",
      "500: 0.2698187670025672\n",
      "514: 0.0116654822071062\n",
      "1916: 0.6352135079828706\n",
      "502: 0.2340274522060739\n",
      "10027: 0.90715667311412\n",
      "10033: 0.2451609692989004\n",
      "1733: 0.155114715767938\n",
      "884: 0.7777165712749977\n",
      "2158: 0.008598228243877\n",
      "310: 0.0041273746737654\n",
      "1109: 0.0043947178479692445\n",
      "1121: 0.5495367748741593\n",
      "1135: 0.32928245752671836\n",
      "1134: 0.3812040532485596\n",
      "1120: 0.1445643606645442\n",
      "488: 0.4302649223708913\n",
      "1691: 0.0722881719551314\n",
      "305: 0.005238929\n",
      "477: 0.2853243165767597\n",
      "107: 0.4238700279999999\n",
      "885: 0.7284051076614922\n",
      "1242: 0.0459189943894568\n",
      "1726: 0.1553639210061397\n",
      "10032: 0.7967205304323659\n",
      "1068: 0.11629208645483512\n",
      "10026: 0.4583522422542184\n",
      "517: 0.3118713821419642\n",
      "503: 0.8379147532501132\n",
      "1796: 0.2426096463563349\n",
      "1782: 0.1392823188518659\n",
      "1033: 0.629491577\n",
      "1755: 0.0788479063915031\n",
      "1741: 0.2820472542145361\n",
      "1027: 0.2665154183706976\n",
      "10041: 0.1611633699102712\n",
      "7318: 0.6707545666949875\n",
      "982: 0.36318207421877025\n",
      "1231: 0.5007363277887267\n",
      "969: 0.0062299750800996\n",
      "955: 0.1917692165658364\n",
      "1219: 0.46399720796411187\n",
      "612: 0.05599799463378857\n",
      "606: 0.1348187903668645\n",
      "160: 0.1431389530408006\n",
      "148: 0.2510142196147013\n",
      "1184: 0.4705944648404404\n",
      "362: 0.0470262611907237\n",
      "438: 0.0161318789932577\n",
      "1634: 0.0721523405512075\n",
      "1152: 0.165630028\n",
      "1620: 0.029099912612874868\n",
      "405: 0.8603345087509304\n",
      "411: 0.0006556518308152\n",
      "60: 0.0679053454093411\n",
      "613: 0.3396555648281617\n",
      "1218: 0.4708141881214596\n",
      "798: 0.22745861868189757\n",
      "968: 0.2078539435318658\n",
      "983: 0.2725100363219269\n",
      "1595: 0.00040795784689760003\n",
      "767: 0.031657355679702\n",
      "10040: 0.0\n",
      "1768: 0.6510499214684753\n",
      "1740: 0.0721523405512075\n",
      "1026: 0.49943356571662906\n",
      "1032: 0.246359054\n",
      "1754: 0.6560582808496159\n",
      "1783: 0.7455679622352774\n",
      "203: 0.0\n",
      "1797: 0.6236041052789292\n",
      "1781: 0.12552815439804588\n",
      "567: 0.4054182435077645\n",
      "1742: 0.2696833134600547\n",
      "1756: 0.3276942709857749\n",
      "10042: 0.576692825\n",
      "981: 0.0587341517829113\n",
      "605: 0.030494278954204604\n",
      "89: 0.0271077779682136\n",
      "836: 0.5131208659049911\n",
      "361: 0.0002691235131598\n",
      "413: 0.0\n",
      "1636: 0.1797993607626508\n",
      "1144: 0.07074143199999999\n",
      "1145: 0.178738250203995\n",
      "1151: 0.338983573\n",
      "1804: 0.7998901726552696\n",
      "374: 0.0019294840221836002\n",
      "1186: 0.2376075269999999\n",
      "1192: 0.3647558567303333\n",
      "837: 0.2512172767371255\n",
      "63: 0.0487685950077407\n",
      "88: 0.0\n",
      "604: 0.0287487006237006\n",
      "957: 0.47866531850353894\n",
      "980: 0.2016432496278945\n",
      "1019: 0.0392991169759689\n",
      "572: 0.1350165724312731\n",
      "214: 0.07228604264596353\n",
      "210: 0.31024918170008964\n",
      "1790: 0.5019693309526311\n",
      "204: 0.3488033399679596\n",
      "1021: 0.00018061674008810002\n",
      "1035: 0.5069817500301537\n",
      "1753: 0.2892046035599459\n",
      "774: 0.2988825103679339\n",
      "1586: 0.0051226022244265\n",
      "1592: 0.0336408912675846\n",
      "1237: 0.11439031899999999\n",
      "600: 0.11139788477171789\n",
      "614: 0.0\n",
      "1800: 0.3991800128080517\n",
      "1828: 0.5492512735378581\n",
      "1182: 0.0987264919626151\n",
      "416: 0.1538533305892845\n",
      "370: 0.37567032368853975\n",
      "1183: 0.5083880402625932\n",
      "1829: 0.5769556587751429\n",
      "1197: 0.455349889\n",
      "1801: 0.2987620461829292\n",
      "198: 0.0353189947446572\n",
      "99: 0.0254479515628361\n",
      "601: 0.4225175267968713\n",
      "629: 0.8063378151876002\n",
      "1236: 0.0\n",
      "1587: 0.0249908236333434\n",
      "991: 0.030068057014552303\n",
      "1752: 0.3001603123030513\n",
      "1020: 0.0\n",
      "1791: 0.639944818311355\n",
      "549: 0.047281847\n",
      "575: 0.1182374618941872\n",
      "1787: 0.2045461035437904\n",
      "1036: 0.47509687599999995\n",
      "1744: 0.38380223073081404\n",
      "987: 0.2192049364451352\n",
      "993: 0.000356947082595\n",
      "777: 0.06031889776512821\n",
      "978: 0.1874845633967263\n",
      "1220: 0.219833393\n",
      "165: 0.19608588257647733\n",
      "603: 0.163326093\n",
      "1817: 0.5350485329803661\n",
      "373: 0.2282563438784993\n",
      "1181: 0.4592518893835221\n",
      "415: 0.7302742886439374\n",
      "367: 0.0262045030712036\n",
      "398: 0.147449035186493\n",
      "1631: 0.4557628671598731\n",
      "399: 0.10003895092183838\n",
      "1619: 0.343948114781448\n",
      "1194: 0.204266846\n",
      "372: 0.0\n",
      "616: 0.7358625474074968\n",
      "789: 0.2834711830304831\n",
      "1023: 0.2323716189999999\n",
      "1037: 0.323683583\n",
      "7308: 0.7662102039475616\n",
      "574: 0.0693024540956017\n",
      "1786: 0.8199948927477015\n"
     ]
    }
   ],
   "source": [
    "for col in df_storage_assimilation.columns:\n",
    "    smin = df_storage_assimilation.loc[df_storage_assimilation[col]>=0, col].min()\n",
    "    smax = df_storage_assimilation.loc[df_storage_assimilation[col]>=0, col].max()\n",
    "    print(f'{col}: {smin/smax}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '1980-01-01'\n",
    "end_date = '1980-12-31'\n",
    "\n",
    "t = 100\n",
    "date = pd.date_range(start_date, end_date)[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date.month == 4 and date.day == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.to_datetime('2003-01-20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time\n",
       "2003-01-20    3301.0\n",
       "2003-01-20    3301.0\n",
       "Name: 99, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_storage_assimilation.loc[date, '99']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['545', '223', '1774', '7311', '1006', '592', '753', '784', '948', '974',\n",
       "       ...\n",
       "       '1619', '1194', '372', '616', '789', '1023', '1037', '7308', '574',\n",
       "       '1786'],\n",
       "      dtype='object', length=452)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_storage_assimilation.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
