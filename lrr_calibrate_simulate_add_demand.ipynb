{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lrr_prototype as lrr\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/Users/donghui/Box Sync/Research/PhD/Projects/Water_Supply_Drought'\n",
    "data_dir = f'{base_dir}/data'\n",
    "reservoir_data_dir = '/Users/donghui/Box Sync/Research/PhD/Projects/DROM_CONUS_Analysis/Data/HydroShare'\n",
    "output_dir = f'{data_dir}/results/lrr_output'\n",
    "\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Prepare the model run for a specific basin ---- #\n",
    "\n",
    "huc4 = '1709'\n",
    "\n",
    "# constant parameters\n",
    "grid_length = 111 / 8    # grid length (km)\n",
    "\n",
    "# simulation period\n",
    "start_date = '1988-01-01'\n",
    "end_date = '2019-12-31'\n",
    "\n",
    "# define run directory\n",
    "run_dir = f'/Users/donghui/Box Sync/Research/PhD/Projects/Water_Supply_Drought/data/results/lrr_output/{huc4}'\n",
    "if not os.path.exists(run_dir):\n",
    "    os.makedirs(run_dir)\n",
    "\n",
    "# reservoir storage file path - for assimilation\n",
    "reservoir_storage_file_path = '/Users/donghui/Box Sync/Research/PhD/Projects/Water_Supply_Drought/data/processed/LRR/input/reservoir_storage.csv'\n",
    "\n",
    "# read conus grid nc\n",
    "conus_grid_nc_path = '/Users/donghui/Box Sync/Research/PhD/Projects/Water_Supply_Drought/data/processed/LRR/input/conus_nldas_grid.nc'\n",
    "lat_array_conus, lon_array_conus, grid_id_array_conus, flow_dir_array_conus = lrr.read_conus_grid_nc(conus_grid_nc_path)\n",
    "\n",
    "# read conus reservoir nc\n",
    "conus_res_nc_path = '/Users/donghui/Box Sync/Research/PhD/Projects/Water_Supply_Drought/data/processed/LRR/input/reservoirs.nc'\n",
    "res_gid_array, res_grid_id_array, res_max_storage_array, res_lat_array, res_lon_array = lrr.read_conus_reservoir_nc(conus_res_nc_path)\n",
    "\n",
    "# read huc4 basin\n",
    "nhd_data_dir = '/Users/donghui/Box Sync/Research/PhD/Projects/Drought_Cycle_Analysis/Data'\n",
    "gdf_huc2_conus, gdf_huc4_conus, gdf_huc4 = lrr.read_huc4_basin(huc4, nhd_data_dir)\n",
    "\n",
    "# get grids in huc4\n",
    "gdf_huc4_points, lon_index_array, lat_index_array = lrr.get_grids_in_hu(lon_array_conus, lat_array_conus, gdf_huc4)\n",
    "\n",
    "# sort grids by flow direction\n",
    "upstream_grid_dict, upstream_grid_id_dict, G, flow_dir_array_huc4 = lrr.sort_grids_by_flow_dir(flow_dir_array_conus, gdf_huc4_points, grid_id_array_conus, lat_array_conus, lon_array_conus)\n",
    "\n",
    "# read nldas runoff\n",
    "nldas_runoff_nc_path = '/Users/donghui/Box Sync/Research/PhD/Projects/Water_Supply_Drought/data/processed/LRR/input/nldas_runoff.nc'\n",
    "nldas_qs_array, nldas_qsb_array = lrr.read_nldas_runoff(nldas_runoff_nc_path, lat_index_array, lon_index_array, start_date, end_date)    # [time, lat, lon]\n",
    "\n",
    "# read gcam water demand\n",
    "gcam_demand_file_path = '/Users/donghui/Box Sync/Research/PhD/Projects/Water_Supply_Drought/data/processed/LRR/input/total_consumption_conus.nc'\n",
    "total_demand_array = lrr.read_gcam_demand(gcam_demand_file_path, lat_index_array, lon_index_array, start_date, end_date)\n",
    "\n",
    "# read pdsi\n",
    "pdsi_file_path = f'/Users/donghui/Box Sync/Research/PhD/Projects/Water_Supply_Drought/data/processed/LRR/input/pdsi_{huc4}.csv'\n",
    "pdsi_array = lrr.read_pdsi(pdsi_file_path, start_date, end_date)\n",
    "\n",
    "# prepare doy array\n",
    "doy_array = pd.date_range(start_date, end_date).dayofyear.values\n",
    "\n",
    "# save variables\n",
    "# save_var_list = [\n",
    "#     'grid_id', 'reservoir_id', 'reservoir_storage_start', 'reservoir_storage_end', 'outflow_before_operation', 'outflow_after_operation', \n",
    "#     'grid_storage_start', 'grid_storage_end', 'flow_direction']\n",
    "save_var_list = []    # don't save any variables, just for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Calculate model metric for each run ---- #\n",
    "\n",
    "def calculate_run_metric(\n",
    "        model_states: list,    # model states\n",
    "        start_date: str,    # start date of the simulation\n",
    "        end_date: str,    # end date of the simulation\n",
    "        start_date_calibration: str,    # start date of the calibration period\n",
    "        end_date_calibration: str,    # end date of the calibration period\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Calculate model metric for each run.\n",
    "        The metric is based on the reservoir release.\n",
    "    \n",
    "    Return:\n",
    "        metric_list: [[reservoir_id, r2_release, pbias_release, nrmse_release], [...], ...]\n",
    "        df_reservoir_ts: dataframe of reservoir time series\n",
    "    \"\"\"\n",
    "\n",
    "    date_list = pd.date_range(start_date, end_date, freq='D').strftime(\"%Y-%m-%d\").tolist()\n",
    "    # check if the date list is the same as the model states\n",
    "    if len(date_list) != len(model_states):\n",
    "        raise ValueError('The length of the date list is not the same as the model states.')\n",
    "\n",
    "    # Access the first model state to get grid attributes\n",
    "    grid_id = model_states[0]['grid_id'][:, :].astype(int)\n",
    "    flow_dir_grid = model_states[0]['flow_direction'][:, :].astype(int)\n",
    "    reservoir_id_grid = model_states[0]['reservoir_id'][:, :].astype(int)\n",
    "\n",
    "    reservoir_in_huc4_id = np.unique(reservoir_id_grid[(flow_dir_grid!=-1) & (reservoir_id_grid!=0)])    # get the reservoir id in the huc4 basin\n",
    "    # Create dictionary to store reservoir time series\n",
    "    reservoir_ts_dict = {'date': pd.to_datetime(date_list)}\n",
    "    for reservoir_id in reservoir_in_huc4_id:\n",
    "        reservoir_ts_dict[f'reservoir_{reservoir_id}_storage_start'] = np.zeros(len(date_list))\n",
    "        reservoir_ts_dict[f'reservoir_{reservoir_id}_storage_end'] = np.zeros(len(date_list))\n",
    "        reservoir_ts_dict[f'reservoir_{reservoir_id}_inflow'] = np.zeros(len(date_list))\n",
    "        reservoir_ts_dict[f'reservoir_{reservoir_id}_release'] = np.zeros(len(date_list))\n",
    "\n",
    "    # Loop through each model state\n",
    "    for i, date in enumerate(date_list):\n",
    "        ds = model_states[i]\n",
    "        reservoir_storage_start_grid = ds['reservoir_storage_start'][:, :]\n",
    "        reservoir_storage_end_grid = ds['reservoir_storage_end'][:, :]\n",
    "        outflow_before_operation_grid = ds['outflow_before_operation'][:, :]\n",
    "        outflow_after_operation_grid = ds['outflow_after_operation'][:, :]\n",
    "\n",
    "        for reservoir_id in reservoir_in_huc4_id:\n",
    "            reservoir_ts_dict[f'reservoir_{reservoir_id}_storage_start'][i] = reservoir_storage_start_grid[reservoir_id_grid==reservoir_id]\n",
    "            reservoir_ts_dict[f'reservoir_{reservoir_id}_storage_end'][i] = reservoir_storage_end_grid[reservoir_id_grid==reservoir_id]\n",
    "\n",
    "            grid_id_associated = grid_id[reservoir_id_grid==reservoir_id][0]    # get the grid id associated with the reservoir\n",
    "            inflow = outflow_before_operation_grid[grid_id==grid_id_associated][0]    # get the inflow from the grid: outflow_before_operation\n",
    "            release = outflow_after_operation_grid[grid_id==grid_id_associated][0]    # get the release from the grid: outflow_after_operation\n",
    "            reservoir_ts_dict[f'reservoir_{reservoir_id}_inflow'][i] = inflow * 3600 * 24 * 0.000810714    # convert from m3/s to acft/day\n",
    "            reservoir_ts_dict[f'reservoir_{reservoir_id}_release'][i] = release * 3600 * 24 * 0.000810714    # convert from m3/s to acft/day\n",
    "\n",
    "    # Convert dictionary to dataframe\n",
    "    df_reservoir_ts = pd.DataFrame(reservoir_ts_dict)\n",
    "    df_reservoir_ts.set_index('date', inplace=True)\n",
    "\n",
    "    # Read reservoir metadata\n",
    "    df_res_meta = pd.read_excel(f'{data_dir}/processed/reservoir_metadata.xlsx')\n",
    "\n",
    "    # Calculate metrics & store\n",
    "    metric_list = []    # [[reservoir_id, r2_release, pbias_release, nrmse_release], [...], ...]\n",
    "    # Read observed release & add to df_reservoir_ts\n",
    "    for reservoir_id in reservoir_in_huc4_id:\n",
    "        df_reservoir_ts[f'reservoir_{reservoir_id}_observed_release'] = np.nan\n",
    "        df_reservoir_ts[f'reservoir_{reservoir_id}_observed_storage_start'] = np.nan\n",
    "        df_reservoir_ts[f'reservoir_{reservoir_id}_observed_inflow'] = np.nan\n",
    "\n",
    "        reservoir_smax = df_res_meta.loc[df_res_meta['ID']==reservoir_id, 'Maximum Storage'].values[0]\n",
    "        df_ts = pd.read_csv(f'{reservoir_data_dir}/data_training/{reservoir_id}.csv')\n",
    "        df_ts[['Storage', 'NetInflow', 'Release']] = df_ts[['Storage', 'NetInflow', 'Release']] * reservoir_smax\n",
    "        df_ts['Time'] = pd.to_datetime(df_ts['Time'])\n",
    "        df_ts.set_index('Time', inplace=True)\n",
    "        # if df_ts has duplicate index, drop the duplicate. This can happen when observations have the same date mistakenly.\n",
    "        if df_ts.index.duplicated().any():\n",
    "            df_ts = df_ts[~df_ts.index.duplicated(keep='first')]\n",
    "\n",
    "        # add observed release to df_reservoir_ts\n",
    "        df_reservoir_ts.loc[start_date:end_date, f'reservoir_{reservoir_id}_observed_release'] = df_ts['Release']\n",
    "        df_reservoir_ts.loc[start_date:end_date, f'reservoir_{reservoir_id}_observed_storage_start'] = df_ts['Storage']\n",
    "        df_reservoir_ts.loc[start_date:end_date, f'reservoir_{reservoir_id}_observed_inflow'] = df_ts['NetInflow']\n",
    "\n",
    "        # Calculate metrics\n",
    "        # # drop nan\n",
    "        # df_reservoir_ts_dropna = df_reservoir_ts.dropna()\n",
    "\n",
    "        # # access the calibration period\n",
    "        # df_reservoir_ts_dropna = df_reservoir_ts_dropna.loc[start_date_calibration:end_date_calibration]\n",
    "        #### above error: cannot dropna for all existing columns\n",
    "\n",
    "        # drop nan for release of reservoir_id\n",
    "        df_reservoir_ts_dropna = df_reservoir_ts[[f'reservoir_{reservoir_id}_observed_release', f'reservoir_{reservoir_id}_release']].dropna()\n",
    "        # access the calibration period\n",
    "        df_reservoir_ts_dropna = df_reservoir_ts_dropna.loc[start_date_calibration:end_date_calibration]\n",
    "\n",
    "        # 1. r2 score\n",
    "        r2_release = r2_score(df_reservoir_ts_dropna[f'reservoir_{reservoir_id}_observed_release'], df_reservoir_ts_dropna[f'reservoir_{reservoir_id}_release'])\n",
    "\n",
    "        # 2. percent bias\n",
    "        pbias_release = (df_reservoir_ts_dropna[f'reservoir_{reservoir_id}_release'].sum() - df_reservoir_ts_dropna[f'reservoir_{reservoir_id}_observed_release'].sum()) / df_reservoir_ts_dropna[f'reservoir_{reservoir_id}_observed_release'].sum() * 100\n",
    "\n",
    "        # 3. nRMSE\n",
    "        nrmse_release = mean_squared_error(df_reservoir_ts_dropna[f'reservoir_{reservoir_id}_observed_release'], df_reservoir_ts_dropna[f'reservoir_{reservoir_id}_release'], squared=False) / df_reservoir_ts_dropna[f'reservoir_{reservoir_id}_observed_release'].mean()\n",
    "        \n",
    "        # add to metric list\n",
    "        metric_list.append([reservoir_id, r2_release, pbias_release, nrmse_release])\n",
    "\n",
    "    return metric_list, df_reservoir_ts\n",
    "\n",
    "# Test\n",
    "# start_date = '1990-10-01'\n",
    "# end_date = '1992-10-01'\n",
    "# start_date_calibration = '1991-01-01'\n",
    "# end_date_calibration = '1992-10-01'\n",
    "# # initialize grid\n",
    "# nrows, ncols = flow_dir_array_huc4.shape\n",
    "# grid_id_array_huc4 = grid_id_array_conus[np.ix_(lat_index_array, lon_index_array)]\n",
    "# grid = lrr.initialize_grid(nrows, ncols, res_grid_id_array, res_gid_array, res_max_storage_array, grid_id_array_huc4, grid_length, flow_dir_array_huc4)\n",
    "# model_states = lrr.run_simulation(run_dir, grid_length, upstream_grid_dict, grid, start_date, end_date, nldas_qs_array, nldas_qsb_array, pdsi_array, doy_array, save_var_list, u_e)\n",
    "# metric_list, df_reservoir_ts = calculate_run_metric(model_states, start_date, end_date, start_date_calibration, end_date_calibration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Run the model for each grid in the basin ---- #\n",
    "# ---- Modify the parameters here ---- #\n",
    "\n",
    "# define if the demand is considered\n",
    "# usually, the demand is not considered for the calibration, and is considered for the simulation\n",
    "is_demand = True\n",
    "\n",
    "# define range of u_e to test\n",
    "u_e_array = np.arange(0.01, 0.16, 0.01)\n",
    "\n",
    "# define the calibration period\n",
    "start_date_calibration = (pd.to_datetime(start_date) + pd.DateOffset(years=3)).strftime('%Y-%m-%d')    # start date of the calibration period (3 years after the start date), the first 2 years are used for warm up\n",
    "end_date_calibration = end_date\n",
    "\n",
    "# initiliaze metric dictionary for all runs\n",
    "metric_list_all_runs = []    # [[metric_list_run_1], [metric_list_run_2], ...]\n",
    "df_reservoir_ts_all_runs = []    # [df_reservoir_ts_run_1, df_reservoir_ts_run_2, ...]\n",
    "\n",
    "# run the model for each u_e\n",
    "for (i, u_e) in enumerate(u_e_array):\n",
    "    print(f'{i}: Running u_e = {u_e} ...')\n",
    "\n",
    "    # initialize grid\n",
    "    nrows, ncols = flow_dir_array_huc4.shape\n",
    "    grid_id_array_huc4 = grid_id_array_conus[np.ix_(lat_index_array, lon_index_array)]\n",
    "    grid = lrr.initialize_grid(nrows, ncols, res_grid_id_array, res_gid_array, res_max_storage_array, grid_id_array_huc4, grid_length, flow_dir_array_huc4)\n",
    "\n",
    "    # run simulation\n",
    "    model_states = lrr.run_simulation(run_dir, reservoir_storage_file_path, grid_length, upstream_grid_dict, grid, start_date, end_date, nldas_qs_array, nldas_qsb_array, total_demand_array, pdsi_array, doy_array, save_var_list, u_e, is_demand)\n",
    "\n",
    "    # post-process model states\n",
    "    metric_list, df_reservoir_ts = calculate_run_metric(model_states, start_date, end_date, start_date_calibration, end_date_calibration)\n",
    "    metric_list_all_runs.append(metric_list)\n",
    "    df_reservoir_ts_all_runs.append(df_reservoir_ts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Best u_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Plot metrics for all reservoirs for all runs ---- #\n",
    "\n",
    "ind_line = 0\n",
    "\n",
    "# create a dictionary to store NSE for each reservoir: {reservoir_id: [NSE_run_1, NSE_run_2, ...]}\n",
    "nse_dict = {res_metric[0]: [] for res_metric in metric_list}\n",
    "pbias_dict = {res_metric[0]: [] for res_metric in metric_list}\n",
    "nrmse_dict = {res_metric[0]: [] for res_metric in metric_list}\n",
    "\n",
    "# loop through each run\n",
    "for i, metric_list in enumerate(metric_list_all_runs):\n",
    "    # loop through each reservoir\n",
    "    for res_metric in metric_list:\n",
    "        reservoir_id = res_metric[0]\n",
    "        nse = res_metric[1]\n",
    "        nse_dict[reservoir_id].append(nse)\n",
    "        pbias = res_metric[2]\n",
    "        pbias_dict[reservoir_id].append(pbias)\n",
    "        nrmse = res_metric[3]\n",
    "        nrmse_dict[reservoir_id].append(nrmse)\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(15, 4))\n",
    "for reservoir_id, nse_list in nse_dict.items():\n",
    "    ax[0].plot(range(len(u_e_array)), nse_list, label=reservoir_id)\n",
    "    ax[0].set_ylim([-1, 1])\n",
    "    # add a vertical line\n",
    "    ax[0].axvline(x=ind_line, color='red', linestyle='--')\n",
    "    ax[1].plot(range(len(u_e_array)), pbias_dict[reservoir_id], label=reservoir_id)\n",
    "    ax[2].plot(range(len(u_e_array)), nrmse_dict[reservoir_id], label=reservoir_id)\n",
    "    ax[0].legend() \n",
    "# ax.set_xlabel('u_e')\n",
    "# ax.set_ylabel('NSE')\n",
    "# ax.set_title(f'NSE for each reservoir for different u_e')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot to help select best $u_e$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Plot reservoir release simulation for the best run ---- #\n",
    "\n",
    "# # select the index of the best run\n",
    "# u_e_best_index = 4\n",
    "\n",
    "u_e_best_test_list = range(0, 15)\n",
    "\n",
    "for u_e_best_index in u_e_best_test_list:\n",
    "    # get the full simulation of the best run\n",
    "    df_reservoir_ts_best = df_reservoir_ts_all_runs[u_e_best_index]\n",
    "\n",
    "    # plot simulated release vs. observed release for each reservoir\n",
    "    reservoir_id_list = list(set(df_reservoir_ts_best.columns[df_reservoir_ts_best.columns.str.contains('_release')].str.split('_').str[1].tolist()))\n",
    "    for reservoir_id in reservoir_id_list:\n",
    "        fig, ax = plt.subplots(figsize=(15, 4))\n",
    "        ax.plot(df_reservoir_ts_best[f'reservoir_{reservoir_id}_observed_release'], label='observed')\n",
    "        ax.plot(df_reservoir_ts_best[f'reservoir_{reservoir_id}_release'], label='simulated')\n",
    "        ax.set_title(f'Reservoir {reservoir_id}')\n",
    "        ax.legend()\n",
    "\n",
    "        if not os.path.exists(f'{run_dir}/calibration_plots/release'):\n",
    "            os.makedirs(f'{run_dir}/calibration_plots/release')\n",
    "\n",
    "        plt.savefig(f'{run_dir}/calibration_plots/release/reservoir_{reservoir_id}_daily_release_ue={u_e_array[u_e_best_index]:.2f}.jpg', dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "        # plot in monthly scale\n",
    "        fig, ax = plt.subplots(figsize=(15, 4))\n",
    "        df_reservoir_ts_best[f'reservoir_{reservoir_id}_observed_release'].resample('M').mean().plot(label='observed')\n",
    "        df_reservoir_ts_best[f'reservoir_{reservoir_id}_release'].resample('M').mean().plot(label='simulated')\n",
    "        ax.set_title(f'Reservoir {reservoir_id}')\n",
    "        ax.legend()\n",
    "\n",
    "        # if calibration_plots/release folder does not exist, create it\n",
    "        plt.savefig(f'{run_dir}/calibration_plots/release/reservoir_{reservoir_id}_monthly_release_ue={u_e_array[u_e_best_index]:.2f}.jpg', dpi=150)\n",
    "        plt.close() \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rerun With Best u_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Rerun for the best u_e ---- #\n",
    "# ---- Save model states ---- #\n",
    "\n",
    "# best u_e\n",
    "u_e_best_index = 4\n",
    "u_e = u_e_array[u_e_best_index]\n",
    "\n",
    "# define the calibration period\n",
    "start_date_calibration = (pd.to_datetime(start_date) + pd.DateOffset(years=3)).strftime('%Y-%m-%d')    # start date of the calibration period (3 years after the start date), the first 2 years are used for warm up\n",
    "end_date_calibration = end_date\n",
    "\n",
    "# initiliaze metric dictionary for all runs\n",
    "metric_list_all_runs = []    # [[metric_list_run_1], [metric_list_run_2], ...]\n",
    "df_reservoir_ts_all_runs = []    # [df_reservoir_ts_run_1, df_reservoir_ts_run_2, ...]\n",
    "\n",
    "# run the model for each u_e\n",
    "print(f'{i}: Running u_e = {u_e} ...')\n",
    "\n",
    "# initialize grid\n",
    "nrows, ncols = flow_dir_array_huc4.shape\n",
    "grid_id_array_huc4 = grid_id_array_conus[np.ix_(lat_index_array, lon_index_array)]\n",
    "grid = lrr.initialize_grid(nrows, ncols, res_grid_id_array, res_gid_array, res_max_storage_array, grid_id_array_huc4, grid_length, flow_dir_array_huc4)\n",
    "\n",
    "# run simulation\n",
    "model_states = lrr.run_simulation(run_dir, reservoir_storage_file_path, grid_length, upstream_grid_dict, grid, start_date, end_date, nldas_qs_array, nldas_qsb_array, total_demand_array, pdsi_array, doy_array, save_var_list, u_e, is_demand)\n",
    "\n",
    "# post-process model states\n",
    "metric_list, df_reservoir_ts = calculate_run_metric(model_states, start_date, end_date, start_date_calibration, end_date_calibration)\n",
    "metric_list_all_runs.append(metric_list)\n",
    "df_reservoir_ts_all_runs.append(df_reservoir_ts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Save model states ---- #\n",
    "\n",
    "save_var_list_nontime = ['grid_id', 'reservoir_id', 'flow_direction']\n",
    "save_var_list_time = [\n",
    "    'reservoir_storage_start', 'reservoir_storage_end', 'outflow_before_operation', 'outflow_after_operation', \n",
    "    'grid_storage_start', 'grid_storage_end', 'total_water_demand', 'water_deficit'\n",
    "]\n",
    "\n",
    "# save model states to nc using netcdf4\n",
    "nc_save_path = f'{run_dir}/model_states_{huc4}.nc'\n",
    "timestamp = pd.date_range(start_date, end_date, freq='D').strftime(\"%Y-%m-%d\").tolist()\n",
    "with nc.Dataset(nc_save_path, 'w') as ds:\n",
    "    # dimensions\n",
    "    ds.createDimension('time', len(timestamp))\n",
    "    ds.createDimension('lat', nrows)\n",
    "    ds.createDimension('lon', ncols)\n",
    "\n",
    "    # variables\n",
    "    # non-time variables\n",
    "    ds.createVariable('time', 'str', ('time',))\n",
    "    ds.createVariable('lat', 'float32', ('lat',))\n",
    "    ds.createVariable('lon', 'float32', ('lon',))\n",
    "    ds.createVariable('grid_id', 'int', ('lat', 'lon',))\n",
    "    ds.createVariable('reservoir_id', 'int', ('lat', 'lon',))\n",
    "    ds.createVariable('flow_direction', 'int', ('lat', 'lon',))\n",
    "    # time variables\n",
    "    for var in save_var_list_time:\n",
    "        ds.createVariable(var, 'float32', ('time', 'lat', 'lon',))\n",
    "\n",
    "    # save variables\n",
    "    # non-time variables\n",
    "    ds['time'][:] = np.array(timestamp)\n",
    "    ds['lat'][:] = lat_array_conus[lat_index_array]\n",
    "    ds['lon'][:] = lon_array_conus[lon_index_array]\n",
    "    ds['grid_id'][:] = grid_id_array_huc4\n",
    "    ds['reservoir_id'][:] = grid['reservoir_id']\n",
    "    ds['flow_direction'][:] = grid['flow_direction']\n",
    "    # time variables\n",
    "    for var in save_var_list_time:\n",
    "        ds[var][:] = np.array([model_states[i][var][:, :] for i in range(len(model_states))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Plot reservoir storage simulation for the best run ---- #\n",
    "# ---- using u_e from above ---- #\n",
    "\n",
    "\n",
    "# get the full simulation of the best run\n",
    "df_reservoir_ts_best = df_reservoir_ts_all_runs[0]    # default using 0 if best u_e has been rerun\n",
    "u_e_best = u_e    # using the best u_e from above\n",
    "\n",
    "# plot simulated release vs. observed release for each reservoir\n",
    "reservoir_id_list = list(set(df_reservoir_ts_best.columns[df_reservoir_ts_best.columns.str.contains('_release')].str.split('_').str[1].tolist()))\n",
    "for reservoir_id in reservoir_id_list:\n",
    "    fig, ax = plt.subplots(figsize=(15, 4))\n",
    "    ax.plot(df_reservoir_ts_best[f'reservoir_{reservoir_id}_observed_storage_start'], label='observed')\n",
    "    ax.plot(df_reservoir_ts_best[f'reservoir_{reservoir_id}_storage_start'], label='simulated')\n",
    "    ax.set_title(f'Reservoir {reservoir_id}')\n",
    "    ax.legend()\n",
    "\n",
    "    if not os.path.exists(f'{run_dir}/calibration_plots/storage'):\n",
    "        os.makedirs(f'{run_dir}/calibration_plots/storage')\n",
    "    # plt.savefig(f'{run_dir}/calibration_plots/storage/reservoir_{reservoir_id}_daily_storage_start_ue={u_e_array[u_e_best_index]:.2f}.jpg', dpi=150)\n",
    "    plt.savefig(f'{run_dir}/calibration_plots/storage/reservoir_{reservoir_id}_daily_storage_start_ue={u_e:.2f}.jpg', dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Plot reservoir inflow simulation for the best run ---- #\n",
    "\n",
    "# get the full simulation of the best run\n",
    "df_reservoir_ts_best = df_reservoir_ts_all_runs[0]\n",
    "\n",
    "# plot simulated release vs. observed release for each reservoir\n",
    "reservoir_id_list = list(set(df_reservoir_ts_best.columns[df_reservoir_ts_best.columns.str.contains('_release')].str.split('_').str[1].tolist()))\n",
    "for reservoir_id in reservoir_id_list:\n",
    "    fig, ax = plt.subplots(figsize=(15, 4))\n",
    "    ax.plot(df_reservoir_ts_best[f'reservoir_{reservoir_id}_observed_inflow'], label='observed')\n",
    "    ax.plot(df_reservoir_ts_best[f'reservoir_{reservoir_id}_inflow'], label='simulated')\n",
    "    ax.set_title(f'Reservoir {reservoir_id}')\n",
    "    ax.legend()\n",
    "\n",
    "    if not os.path.exists(f'{run_dir}/calibration_plots/inflow'):\n",
    "        os.makedirs(f'{run_dir}/calibration_plots/inflow')\n",
    "    # plt.savefig(f'{run_dir}/calibration_plots/inflow/reservoir_{reservoir_id}_daily_inflow_ue={u_e_array[u_e_best_index]:.2f}.jpg', dpi=150)\n",
    "    plt.savefig(f'{run_dir}/calibration_plots/inflow/reservoir_{reservoir_id}_daily_inflow_ue={u_e:.2f}.jpg', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "huc4 = '0601'\n",
    "# start_date = '1998-10-01'\n",
    "# end_date = '2018-10-01'\n",
    "start_date = '1980-10-01'\n",
    "end_date = '2000-10-01'\n",
    "date_list = pd.date_range(start_date, end_date, freq='D').strftime(\"%Y-%m-%d\").tolist()\n",
    "\n",
    "# Read the 1st .nc output file to get grid attributes\n",
    "nc_file_path = f'{output_dir}/{huc4}_model_state_{date_list[0]}.nc'\n",
    "with nc.Dataset(nc_file_path) as ds:\n",
    "    grid_id = ds.variables['grid_id'][:, :].astype(int)\n",
    "    flow_dir_grid = ds.variables['flow_direction'][:, :].astype(int)\n",
    "    reservoir_id_grid = ds.variables['reservoir_id'][:, :].astype(int)\n",
    "\n",
    "reservoir_in_huc4_id = np.unique(reservoir_id_grid[(flow_dir_grid!=-1) & (reservoir_id_grid!=0)])    # get the reservoir id in the huc4 basin\n",
    "# Create dictionary to store reservoir time series\n",
    "reservoir_ts_dict = {'date': pd.to_datetime(date_list)}\n",
    "for reservoir_id in reservoir_in_huc4_id:\n",
    "    reservoir_ts_dict[f'reservoir_{reservoir_id}_storage_start'] = np.zeros(len(date_list))\n",
    "    reservoir_ts_dict[f'reservoir_{reservoir_id}_storage_end'] = np.zeros(len(date_list))\n",
    "    reservoir_ts_dict[f'reservoir_{reservoir_id}_inflow'] = np.zeros(len(date_list))\n",
    "    reservoir_ts_dict[f'reservoir_{reservoir_id}_release'] = np.zeros(len(date_list))\n",
    "\n",
    "# Read .nc output file\n",
    "for i, date in enumerate(date_list):\n",
    "    nc_file_path = f'{output_dir}/{huc4}_model_state_{date}.nc'\n",
    "    with nc.Dataset(nc_file_path) as ds:\n",
    "        reservoir_storage_start_grid = ds.variables['reservoir_storage_start'][:, :]\n",
    "        reservoir_storage_end_grid = ds.variables['reservoir_storage_end'][:, :]\n",
    "        outflow_before_operation_grid = ds.variables['outflow_before_operation'][:, :]\n",
    "        outflow_after_operation_grid = ds.variables['outflow_after_operation'][:, :]\n",
    "\n",
    "        for reservoir_id in reservoir_in_huc4_id:\n",
    "            reservoir_ts_dict[f'reservoir_{reservoir_id}_storage_start'][i] = reservoir_storage_start_grid[reservoir_id_grid==reservoir_id]\n",
    "            reservoir_ts_dict[f'reservoir_{reservoir_id}_storage_end'][i] = reservoir_storage_end_grid[reservoir_id_grid==reservoir_id]\n",
    "\n",
    "            grid_id_associated = grid_id[reservoir_id_grid==reservoir_id][0]    # get the grid id associated with the reservoir\n",
    "            inflow = outflow_before_operation_grid[grid_id==grid_id_associated][0]    # get the inflow from the grid: outflow_before_operation\n",
    "            release = outflow_after_operation_grid[grid_id==grid_id_associated][0]    # get the release from the grid: outflow_after_operation\n",
    "            reservoir_ts_dict[f'reservoir_{reservoir_id}_inflow'][i] = inflow * 3600 * 24 * 0.000810714    # convert from m3/s to acft/day\n",
    "            reservoir_ts_dict[f'reservoir_{reservoir_id}_release'][i] = release * 3600 * 24 * 0.000810714    # convert from m3/s to acft/day\n",
    "\n",
    "# Convert dictionary to dataframe\n",
    "df_reservoir_ts = pd.DataFrame(reservoir_ts_dict)\n",
    "df_reservoir_ts.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Check reservoir water balance: storage change = inflow - release ---- #\n",
    "\n",
    "plot_start_date = start_date\n",
    "plot_end_date = end_date\n",
    "for reservoir_id in reservoir_in_huc4_id:\n",
    "    df_reservoir_ts[f'reservoir_{reservoir_id}_storage_change_1'] = df_reservoir_ts[f'reservoir_{reservoir_id}_storage_end'] - df_reservoir_ts[f'reservoir_{reservoir_id}_storage_start']\n",
    "    df_reservoir_ts[f'reservoir_{reservoir_id}_storage_change_2'] = df_reservoir_ts[f'reservoir_{reservoir_id}_inflow'] - df_reservoir_ts[f'reservoir_{reservoir_id}_release']\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    df_reservoir_ts.loc[plot_start_date:plot_end_date, f'reservoir_{reservoir_id}_storage_change_1'].plot(ax=ax, label='storage change 1')\n",
    "    df_reservoir_ts.loc[plot_start_date:plot_end_date, f'reservoir_{reservoir_id}_storage_change_2'].plot(ax=ax, label='storage change 2')\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Check reservoir release against the observed release ---- #\n",
    "\n",
    "# plot_start_date = start_date\n",
    "# plot_end_date = end_date\n",
    "plot_start_date = '1985-10-01'\n",
    "plot_end_date = '2000-10-01'\n",
    "# plot_start_date = '2005-10-01'\n",
    "# plot_end_date = '2018-10-01'\n",
    "\n",
    "# reservoir metadata\n",
    "df_res_meta = pd.read_excel(f'{data_dir}/processed/reservoir_metadata.xlsx')\n",
    "\n",
    "# Read observed release\n",
    "for reservoir_id in reservoir_in_huc4_id:\n",
    "    print(reservoir_id)\n",
    "\n",
    "    df_reservoir_ts[f'reservoir_{reservoir_id}_observed_release'] = np.nan\n",
    "    df_reservoir_ts[f'reservoir_{reservoir_id}_observed_storage_start'] = np.nan\n",
    "    df_reservoir_ts[f'reservoir_{reservoir_id}_observed_inflow'] = np.nan\n",
    "\n",
    "    reservoir_smax = df_res_meta.loc[df_res_meta['ID']==reservoir_id, 'Maximum Storage'].values[0]\n",
    "    df_ts = pd.read_csv(f'{reservoir_data_dir}/data_training/{reservoir_id}.csv')\n",
    "    df_ts[['Storage', 'NetInflow', 'Release']] = df_ts[['Storage', 'NetInflow', 'Release']] * reservoir_smax\n",
    "    df_ts['Time'] = pd.to_datetime(df_ts['Time'])\n",
    "    df_ts.set_index('Time', inplace=True)\n",
    "\n",
    "    # add observed release to df_reservoir_ts\n",
    "    df_reservoir_ts.loc[start_date:end_date, f'reservoir_{reservoir_id}_observed_release'] = df_ts['Release']\n",
    "    df_reservoir_ts.loc[start_date:end_date, f'reservoir_{reservoir_id}_observed_storage_start'] = df_ts['Storage']\n",
    "    df_reservoir_ts.loc[start_date:end_date, f'reservoir_{reservoir_id}_observed_inflow'] = df_ts['NetInflow']\n",
    "\n",
    "    # Calculate metrics\n",
    "    # drop nan\n",
    "    df_reservoir_ts_dropna = df_reservoir_ts.dropna()\n",
    "    # 1. r2 score\n",
    "    r2_release = r2_score(df_reservoir_ts_dropna[f'reservoir_{reservoir_id}_observed_release'], df_reservoir_ts_dropna[f'reservoir_{reservoir_id}_release'])\n",
    "\n",
    "    # 2. percent bias\n",
    "    pbias_release = (df_reservoir_ts_dropna[f'reservoir_{reservoir_id}_release'].sum() - df_reservoir_ts_dropna[f'reservoir_{reservoir_id}_observed_release'].sum()) / df_reservoir_ts_dropna[f'reservoir_{reservoir_id}_observed_release'].sum() * 100\n",
    "\n",
    "    # 3. nRMSE\n",
    "    nrmse_release = mean_squared_error(df_reservoir_ts_dropna[f'reservoir_{reservoir_id}_observed_release'], df_reservoir_ts_dropna[f'reservoir_{reservoir_id}_release'], squared=False) / df_reservoir_ts_dropna[f'reservoir_{reservoir_id}_observed_release'].mean()\n",
    "    \n",
    "    print(f'r2 score of release: {r2_release}')\n",
    "    print(f'pbias of release: {pbias_release:.2f}')\n",
    "    print(f'nrmse of release: {nrmse_release:.3f}')\n",
    "    # print(f'r2 score of inflow: {r2_inflow}')\n",
    "    # print(f'r2 score of storage: {r2_storage}')\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    df_reservoir_ts.loc[plot_start_date:plot_end_date, f'reservoir_{reservoir_id}_release'].plot(ax=ax, label='release')\n",
    "    df_reservoir_ts.loc[plot_start_date:plot_end_date, f'reservoir_{reservoir_id}_observed_release'].plot(ax=ax, label='observed release')\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reservoir_ts.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Plot for AGU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at Basin Outlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- save outlet flow to csv ---- #\n",
    "outlet_grid_i, outlet_grid_j = list(upstream_grid_dict)[-1]    # get the outlet grid\n",
    "\n",
    "# get outlet flow\n",
    "outlet_flow_list = [model_state['outflow_after_operation'][outlet_grid_i, outlet_grid_j] for model_state in model_states]\n",
    "# convert to acft/day\n",
    "outlet_flow_list = np.array(outlet_flow_list) * 3600 * 24 * 0.000810714\n",
    "\n",
    "# save to csv\n",
    "df_outlet_flow = pd.DataFrame({'date': pd.date_range(start_date, end_date), 'outlet_flow': outlet_flow_list})\n",
    "# df_outlet_flow.to_csv(f'{data_dir}/{huc4}_outlet_flow_without_res.csv', index=False)\n",
    "# df_outlet_flow.to_csv(f'{data_dir}/{huc4}_outlet_flow_with_res.csv', index=False)\n",
    "# df_outlet_flow.to_csv(f'{data_dir}/{huc4}_outlet_flow_with_res_without_route.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- plot outlet flow ---- #\n",
    "gauge_obs_df = pd.read_excel(f'{data_dir}/{huc4}_outlet_gage.xlsx')\n",
    "gauge_obs_df['discharge_acft'] = gauge_obs_df['discharge'] * 3600 * 24 * 2.29569e-5    # convert from cfs to acft/day\n",
    "gauge_obs_df['date'] = pd.to_datetime(gauge_obs_df['date'])\n",
    "\n",
    "simflow_with_res_df = pd.read_csv(f'{data_dir}/{huc4}_outlet_flow_with_res.csv')\n",
    "simflow_with_res_df['date'] = pd.to_datetime(simflow_with_res_df['date'])\n",
    "\n",
    "simflow_without_res_df = pd.read_csv(f'{data_dir}/{huc4}_outlet_flow_without_res.csv')\n",
    "simflow_without_res_df['date'] = pd.to_datetime(simflow_without_res_df['date'])\n",
    "\n",
    "# plot outlet flow\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.plot(gauge_obs_df['date'], gauge_obs_df['discharge_acft'], label='Observed')\n",
    "ax.plot(simflow_with_res_df['date'], simflow_with_res_df['outlet_flow'], label='Simulated with reservoirs')\n",
    "ax.plot(simflow_without_res_df['date'], simflow_without_res_df['outlet_flow'], label='Simulated without reservoirs')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at Release From Specific Reservoirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- save release from specific reservoir ---- #\n",
    "\n",
    "reservoir_id_list = list(set(df_reservoir_ts.columns[df_reservoir_ts.columns.str.contains('_release')].str.split('_').str[1].tolist()))\n",
    "reservoir_id_list = [int(reservoir_id) for reservoir_id in reservoir_id_list]\n",
    "\n",
    "res_release_dict = {gid: [] for gid in reservoir_id_list}\n",
    "for gid in reservoir_id_list:\n",
    "    grid_i, grid_j = np.where(grid['reservoir_id']==gid)\n",
    "    grid_i = grid_i[0]\n",
    "    grid_j = grid_j[0]\n",
    "\n",
    "    # get reservoir release\n",
    "    reservoir_release_list = [model_state['outflow_after_operation'][grid_i, grid_j] for model_state in model_states]\n",
    "    # convert to acft/day\n",
    "    reservoir_release_list = np.array(reservoir_release_list) * 3600 * 24 * 0.000810714\n",
    "\n",
    "    res_release_dict[gid] = reservoir_release_list\n",
    "\n",
    "# convert to dataframe\n",
    "# add date\n",
    "res_release_df = pd.DataFrame(res_release_dict)\n",
    "res_release_df['date'] = pd.date_range(start_date, end_date)\n",
    "\n",
    "# save to csv\n",
    "# res_release_df.to_csv(f'{data_dir}/{huc4}_res_release_without_res.csv', index=False)\n",
    "# res_release_df.to_csv(f'{data_dir}/{huc4}_res_release_with_res.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- plot cdf for each reservoir ---- #\n",
    "\n",
    "release_with_res_df = pd.read_csv(f'{data_dir}/{huc4}_res_release_with_res.csv')\n",
    "release_with_res_df['date'] = pd.to_datetime(release_with_res_df['date'])\n",
    "release_with_res_df.set_index('date', inplace=True)\n",
    "release_without_res_df = pd.read_csv(f'{data_dir}/{huc4}_res_release_without_res.csv')\n",
    "release_without_res_df['date'] = pd.to_datetime(release_without_res_df['date'])\n",
    "release_without_res_df.set_index('date', inplace=True)\n",
    "\n",
    "reservoir_id_list = [int(reservoir_id) for reservoir_id in reservoir_id_list]\n",
    "\n",
    "# plot ecdf\n",
    "for gid in reservoir_id_list:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.plot(df_reservoir_ts[f'reservoir_{gid}_observed_release'].sort_values(), np.arange(1, len(release_without_res_df)+1) / len(release_without_res_df), label='Observed')\n",
    "    ax.plot(np.sort(release_without_res_df[f'{gid}']), np.arange(1, len(release_without_res_df)+1) / len(release_without_res_df), label='Simulated without reservoirs')\n",
    "    ax.plot(np.sort(release_with_res_df[f'{gid}']), np.arange(1, len(release_with_res_df)+1) / len(release_with_res_df), label='Simulated with reservoirs')\n",
    "\n",
    "    ax.set_title(f'Reservoir {gid}')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "# plot time series\n",
    "for gid in reservoir_id_list:\n",
    "    if gid != 367:\n",
    "        continue\n",
    "    fig, ax = plt.subplots(figsize=(15, 5))\n",
    "    ax.plot(df_reservoir_ts[f'reservoir_{gid}_observed_release'], label='Observed')\n",
    "    ax.plot(release_without_res_df[f'{gid}'], label='Simulated without reservoirs')\n",
    "    ax.plot(release_with_res_df[f'{gid}'], label='Simulated with reservoirs')\n",
    "\n",
    "    ax.set_title(f'Reservoir {gid}')\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot in One Place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString\n",
    "\n",
    "# ---- Prepare flow line ---- #\n",
    "\n",
    "########## Prepare flow lines ##########\n",
    "\n",
    "huc2 = huc4[0:2]\n",
    "crs = 'epsg:4326'\n",
    "gdf_huc4 = gdf_huc4.copy()\n",
    "gdf_huc4.set_crs(crs, inplace=True, allow_override=True)\n",
    "\n",
    "if huc2 == '03':    # multiple NHDP files for 03\n",
    "    flow_attr_file_list = [f'{nhd_data_dir}/Raw/NHDPlus/NHDPlus{huc2}{i}/NHDPlusAttributes' for i in ['N','S','W']]\n",
    "    hydro_file_list = [f'{nhd_data_dir}/Raw/NHDPlus/NHDPlus{huc2}{i}/NHDSnapshot/Hydrography' for i in ['N','S','W']]\n",
    "elif huc2 == '10': \n",
    "    flow_attr_file_list = [f'{nhd_data_dir}/Raw/NHDPlus/NHDPlus{huc2}{i}/NHDPlusAttributes' for i in ['U','L']]\n",
    "    hydro_file_list = [f'{nhd_data_dir}/Raw/NHDPlus/NHDPlus{huc2}{i}/NHDSnapshot/Hydrography' for i in ['U','L']]\n",
    "else:\n",
    "    flow_attr_file_list = [f'{nhd_data_dir}/Raw/NHDPlus/NHDPlus{huc2}/NHDPlusAttributes']\n",
    "    hydro_file_list = [f'{nhd_data_dir}/Raw/NHDPlus/NHDPlus{huc2}/NHDSnapshot/Hydrography']\n",
    "\n",
    "gdf_flow_list = []\n",
    "for flow_attr_file, hydro_file in zip(flow_attr_file_list, hydro_file_list):\n",
    "    gdf_fline_vaa = gpd.read_file(flow_attr_file, layer='PlusFlowlineVAA')\n",
    "    gdf_fline = gpd.read_file(hydro_file, layer='NHDFlowline')\n",
    "\n",
    "    # change COMID to ComID if the error exists\n",
    "    if not 'ComID' in gdf_fline:\n",
    "        gdf_fline.rename(columns={'COMID':'ComID'}, inplace=True)\n",
    "\n",
    "    # change vaa file ComID to int\n",
    "    to_int_var = ['ComID', 'StreamOrde', 'StreamCalc']\n",
    "    gdf_fline_vaa[to_int_var] = gdf_fline_vaa[to_int_var].astype(int)\n",
    "\n",
    "    # merge this two gdfs\n",
    "    to_merge_vars = ['ComID', 'StreamOrde', 'StreamCalc', 'FromNode', 'ToNode']\n",
    "    gdf_flow = gdf_fline.merge(gdf_fline_vaa[to_merge_vars], how='inner', on='ComID')\n",
    "    \n",
    "    gdf_flow_list.append(gdf_flow)\n",
    "\n",
    "gdf_flow = pd.concat(gdf_flow_list)\n",
    "\n",
    "# set crs\n",
    "gdf_flow = gdf_flow.set_crs(crs, inplace=True, allow_override=True)\n",
    "\n",
    "# subset to the target huc4\n",
    "gdf_flow_huc4 = gdf_flow.sjoin(gdf_huc4, how='inner', predicate='intersects')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Visualize the graph on the map ---- #\n",
    "\n",
    "res_metadata_df = pd.read_excel(f'{data_dir}/processed/reservoir_metadata.xlsx')\n",
    "\n",
    "nodes_data = pd.DataFrame.from_dict(dict(G.nodes(data=True)), orient='index')\n",
    "geometry = [Point(xy) for xy in zip(nodes_data['grid_lon'], nodes_data['grid_lat'])]\n",
    "gdf_nodes = gpd.GeoDataFrame(nodes_data, geometry=geometry, crs='EPSG:4326')\n",
    "\n",
    "lon_array_huc4 = np.unique(gdf_nodes['grid_lon'].values)\n",
    "lat_array_huc4 = np.unique(gdf_nodes['grid_lat'].values)\n",
    "\n",
    "# ------------------- Plot ------------------- #\n",
    "# Variables to store components of arrows\n",
    "x = []\n",
    "y = []\n",
    "dx = []\n",
    "dy = []\n",
    "\n",
    "default_lon = lon_array_huc4[0]\n",
    "default_lat = lat_array_huc4[0]\n",
    "for edge in G.edges():\n",
    "    start_node = G.nodes[edge[0]]\n",
    "    end_node = G.nodes[edge[1]]\n",
    "    try:\n",
    "        x_start, y_start = start_node['grid_lon'], start_node['grid_lat']\n",
    "        x_end, y_end = end_node['grid_lon'], end_node['grid_lat']\n",
    "    except KeyError:\n",
    "        x_start, y_start = default_lon, default_lat\n",
    "        x_end, y_end = default_lon, default_lat\n",
    "\n",
    "    x.append(x_start)\n",
    "    y.append(y_start)\n",
    "    dx.append(x_end - x_start)\n",
    "    dy.append(y_end - y_start)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(15, 10))\n",
    "\n",
    "# Plot basin and actual flow\n",
    "gdf_huc4.plot(ax=ax[0], facecolor='whitesmoke', edgecolor='tab:gray', linewidth=1)\n",
    "\n",
    "# plot flow line\n",
    "# specify to which stream order\n",
    "max_order = gdf_flow_huc4['StreamOrde'].max()\n",
    "min_order_to_keep = 4\n",
    "gdf_flow_huc4.loc[gdf_flow_huc4['StreamOrde']>=min_order_to_keep].plot(ax=ax[0], linewidth=1)\n",
    "\n",
    "gdf_huc4.plot(ax=ax[1], facecolor='whitesmoke', edgecolor='tab:gray', linewidth=1)\n",
    "\n",
    "# Plot nodes\n",
    "gdf_nodes.plot(ax=ax[1], marker='o', color='black', alpha=0.7, markersize=10)\n",
    "\n",
    "# Plot arrows\n",
    "ax[1].quiver(x, y, dx, dy, angles='xy', scale_units='xy', scale=1, color='tab:blue')\n",
    "\n",
    "# # Plot all reservoirs\n",
    "# reservoir_id_list = list(set(df_reservoir_ts.columns[df_reservoir_ts.columns.str.contains('_release')].str.split('_').str[1].tolist()))\n",
    "# reservoir_id_list = [int(reservoir_id) for reservoir_id in reservoir_id_list]\n",
    "\n",
    "# for reservoir_id in reservoir_id_list:\n",
    "#     reservoir_i, reservoir_j = np.where(grid['reservoir_id']==reservoir_id)\n",
    "#     reservoir_i = reservoir_i[0]\n",
    "#     reservoir_j = reservoir_j[0]\n",
    "#     res_lat = res_metadata_df.loc[res_metadata_df['ID']==reservoir_id, 'lattitude'].values[0]\n",
    "#     res_lon = res_metadata_df.loc[res_metadata_df['ID']==reservoir_id, 'longtitude'].values[0]\n",
    "\n",
    "#     # plot reservoir\n",
    "#     if reservoir_id == 367:\n",
    "#         ax[0].scatter(res_lon, res_lat, marker='^', color='tab:red', s=100, label='Reservoir')\n",
    "#     else:\n",
    "#         ax[0].scatter(res_lon, res_lat, marker='^', color='tab:red', s=100)\n",
    "\n",
    "# ax[0].legend()\n",
    "\n",
    "# ax[0].set_title('Middle Snake River Basin')\n",
    "ax[0].set_xlabel('Longitude')\n",
    "ax[0].set_ylabel('Latitude')\n",
    "\n",
    "# ax[1].set_title('Middle Snake River Basin - 1/4 degree grid')\n",
    "ax[1].set_xlabel('Longitude')\n",
    "ax[1].set_ylabel('Latitude')\n",
    "\n",
    "# save\n",
    "plt.savefig('/Users/donghui/Box Sync/UIUC/Group Meeting/2024-SPRING/my_presentation/figures/demo_flow_map.jpg', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Plot reservoir 367 time series & cdf ---- #\n",
    "\n",
    "release_with_res_df = pd.read_csv(f'{data_dir}/{huc4}_res_release_with_res.csv')\n",
    "release_with_res_df['date'] = pd.to_datetime(release_with_res_df['date'])\n",
    "release_with_res_df.set_index('date', inplace=True)\n",
    "release_without_res_df = pd.read_csv(f'{data_dir}/{huc4}_res_release_without_res.csv')\n",
    "release_without_res_df['date'] = pd.to_datetime(release_without_res_df['date'])\n",
    "release_without_res_df.set_index('date', inplace=True)\n",
    "\n",
    "reservoir_id_list = [int(reservoir_id) for reservoir_id in reservoir_id_list]\n",
    "\n",
    "# plot time series\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "ax.plot(df_reservoir_ts[f'reservoir_367_observed_release'], label='Observed')\n",
    "ax.plot(release_without_res_df['367'], label='Simulated without reservoirs')\n",
    "ax.plot(release_with_res_df['367'], label='Simulated with reservoirs')\n",
    "\n",
    "ax.set_xlabel('Date', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Streamflow (acft/day)', fontsize=14, fontweight='bold')\n",
    "\n",
    "ax.legend(loc='upper left', fontsize=10)\n",
    "\n",
    "# set upper limit of y axis\n",
    "ax.set_ylim(0, 1800)\n",
    "\n",
    "# plot ecdf within the axix, on the top-right corner\n",
    "# using the matplotlib.axes.Axes.inset_axes method\n",
    "axins = ax.inset_axes([0.78, 0.6, 0.22, 0.4])\n",
    "axins.plot(df_reservoir_ts[f'reservoir_367_observed_release'].sort_values(), np.arange(1, len(release_without_res_df)+1) / len(release_without_res_df), label='Observed')\n",
    "axins.plot(np.sort(release_without_res_df['367']), np.arange(1, len(release_without_res_df)+1) / len(release_without_res_df), label='Simulated without reservoir operation')\n",
    "axins.plot(np.sort(release_with_res_df['367']), np.arange(1, len(release_with_res_df)+1) / len(release_with_res_df), label='Simulated with reservoir operation')\n",
    "\n",
    "axins.set_xlabel('Streamflow', fontweight='bold')\n",
    "axins.set_ylabel('Cumulative Probability', fontweight='bold')\n",
    "\n",
    "# remove axis\n",
    "axins.set_xticklabels([])\n",
    "axins.set_yticklabels([])\n",
    "\n",
    "# add background color\n",
    "axins.patch.set_facecolor('whitesmoke')\n",
    "\n",
    "# save\n",
    "plt.savefig('/Users/donghui/Desktop/time_series_367.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ecdf\n",
    "gid = 367\n",
    "fig, ax = plt.subplots(figsize=(15, 1))\n",
    "ax.plot(df_reservoir_ts[f'reservoir_{gid}_observed_release'].sort_values(), np.arange(1, len(release_without_res_df)+1) / len(release_without_res_df), label='Observed')\n",
    "ax.plot(np.sort(release_without_res_df[f'{gid}']), np.arange(1, len(release_without_res_df)+1) / len(release_without_res_df), label='Simulated without reservoirs')\n",
    "ax.plot(np.sort(release_with_res_df[f'{gid}']), np.arange(1, len(release_with_res_df)+1) / len(release_with_res_df), label='Simulated with reservoirs')\n",
    "\n",
    "ax.set_title(f'Reservoir {gid}')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot time series\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.plot(df_reservoir_ts[f'reservoir_{gid}_observed_release'], label='Observed')\n",
    "ax.plot(release_without_res_df[f'{gid}'], label='Simulated without reservoirs')\n",
    "ax.plot(release_with_res_df[f'{gid}'], label='Simulated with reservoirs')\n",
    "\n",
    "ax.set_title(f'Reservoir {gid}')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
